<style>.itables table td {
    text-overflow: ellipsis;
    overflow: hidden;
}

.itables table th {
    text-overflow: ellipsis;
    overflow: hidden;
}

.itables thead input {
    width: 100%;
    padding: 3px;
    box-sizing: border-box;
}

.itables tfoot input {
    width: 100%;
    padding: 3px;
    box-sizing: border-box;
}
</style>
<div class="itables">
<table id="99d7f90a-d37f-4e27-98da-c6db13822d1b" class="display cell-border"style="width:100%;margin:auto"><thead><th>None</th><th>Rank-Model</th><th>Rank</th><th>Model</th><th>Size</th><th>Format</th><th>Quant</th><th>Context</th><th>Prompt</th><th>1st Score</th><th>2nd Score</th><th>OK</th><th>+/- </th></thead><tbody><tr><td>Loading... (need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td></tr></tbody></table>
<link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/1.13.1/css/jquery.dataTables.min.css">
<script type="module">
    // Import jquery and DataTable
    import 'https://code.jquery.com/jquery-3.6.0.min.js';
    import dt from 'https://cdn.datatables.net/1.12.1/js/jquery.dataTables.mjs';
    dt($);

    // Define the table data
    const data = [["1 \ud83c\udd95", "claude-3-opus-20240229", "[claude-3-opus-20240229](https://www.anthropic.com/claude)", "Claude 3 Opus", "API", "NaN", "NaN", "NaN", "18/18 \u2713", "18/18 \u2713", "\u2717", "\u2713", NaN], ["1", "GPT-4", "[GPT-4](https://www.reddit.com/r/LocalLLaMA/comments/18yp9u4/llm_comparisontest_api_edition_gpt4_vs_gemini_vs/)", "GPT-4", "API", "NaN", "NaN", "NaN", "18/18 \u2713", "18/18 \u2713", "\u2713", "\u2713", NaN], ["1 \ud83c\udd95", "mistral-large-2402", "[mistral-large-2402](https://mistral.ai/)", "Mistral", "API", "NaN", "NaN", "NaN", "18/18 \u2713", "18/18 \u2713", "\u2717", "\u2717", NaN], ["1", "miquliz-120b-v2.0", "[miquliz-120b-v2.0](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "120B", "EXL2", "3.0bpw", "~~32K~~ 4K-12K", "Mistral", "18/18 \u2713", "18/18 \u2713", "\u2713", "\u2713", NaN], ["1", "goliath-120b-GGUF", "[goliath-120b-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "120B", "GGUF", "Q2_K", "4K", "Vicuna 1.1", "18/18 \u2713", "18/18 \u2713", "\u2713", "\u2713", NaN], ["1", "Tess-XL-v1.0-GGUF", "[Tess-XL-v1.0-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "120B", "GGUF", "Q2_K", "4K", "Synthia", "18/18 \u2713", "18/18 \u2713", "\u2713", "\u2713", NaN], ["1", "Nous-Capybara-34B-GGUF", "[Nous-Capybara-34B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "34B", "GGUF", "Q4_0", "16K", "Vicuna 1.1", "18/18 \u2713", "18/18 \u2713", "\u2713", "\u2713", NaN], ["1", "Venus-120b-v1.0", "[Venus-120b-v1.0](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "120B", "EXL2", "3.0bpw", "4K", "Alpaca", "18/18 \u2713", "18/18 \u2713", "\u2713", "\u2717", NaN], ["2", "wolfram/miqu-1-120b", "[wolfram/miqu-1-120b](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "120B", "EXL2", "3.0bpw", "4K", "Mistral", "18/18 \u2713", "18/18 \u2713", "\u2717", "NaN", NaN], ["3", "miquella-120b-3.0bpw-h6-exl2", "[miquella-120b-3.0bpw-h6-exl2](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "120B", "EXL2", "3.0bpw", "~~32K~~ 4K", "Mistral", "18/18 \u2713", "17/18", "\u2713", "\u2713", NaN], ["3", "lzlv_70B-GGUF", "[lzlv_70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", "4K", "Vicuna 1.1", "18/18 \u2713", "17/18", "\u2713", "\u2713", NaN], ["4", "Mixtral_34Bx2_MoE_60B", "[Mixtral_34Bx2_MoE_60B](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "2x34B", "HF", "4-bit", "~~200K~~ 4K", "Alpaca", "18/18 \u2713", "17/18", "\u2713", "\u2717", NaN], ["5", "miquliz-120b-xs.gguf", "[miquliz-120b-xs.gguf](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "120B", "GGUF", "IQ2_XS", "~~32K~~ 4K", "Mistral", "18/18 \u2713", "17/18", "\u2717", "NaN", NaN], ["6", "GPT-4 Turbo", "[GPT-4 Turbo](https://www.reddit.com/r/LocalLLaMA/comments/18yp9u4/llm_comparisontest_api_edition_gpt4_vs_gemini_vs/)", "GPT-4", "API", "NaN", "NaN", "NaN", "18/18 \u2713", "16/18", "\u2713", "\u2713", NaN], ["6", "chronos007-70B-GGUF", "[chronos007-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", "4K", "Alpaca", "18/18 \u2713", "16/18", "\u2713", "\u2713", NaN], ["6", "SynthIA-70B-v1.5-GGUF", "[SynthIA-70B-v1.5-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", "4K", "SynthIA", "18/18 \u2713", "16/18", "\u2713", "\u2713", NaN], ["6", "Gembo-v1-70b-GGUF", "[Gembo-v1-70b-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "70B", "GGUF", "Q5_K_M", "4K", "Alpaca", "18/18 \u2713", "16/18", "\u2713", "NaN", NaN], ["6", "bagel-34b-v0.2", "[bagel-34b-v0.2](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "34B", "HF", "4-bit", "~~200K~~ 4K", "Alpaca", "18/18 \u2713", "16/18", "\u2713", "\u2717", NaN], ["7", "Mixtral-8x7B-Instruct-v0.1", "[Mixtral-8x7B-Instruct-v0.1](https://www.reddit.com/r/LocalLLaMA/comments/18gz54r/llm_comparisontest_mixtral8x7b_mistral_decilm/)", "8x7B", "HF", "4-bit", "~~32K~~ 4K", "Mixtral", "18/18 \u2713", "16/18", "\u2717", "\u2713", NaN], ["8", "dolphin-2_2-yi-34b-GGUF", "[dolphin-2_2-yi-34b-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "34B", "GGUF", "Q4_0", "16K", "ChatML", "18/18 \u2713", "15/18", "\u2717", "\u2717", NaN], ["9", "StellarBright-GGUF", "[StellarBright-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", "4K", "Vicuna 1.1", "18/18 \u2713", "14/18", "\u2713", "\u2713", NaN], ["10", "Dawn-v2-70B-GGUF", "[Dawn-v2-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", "4K", "Alpaca", "18/18 \u2713", "14/18", "\u2713", "\u2717", NaN], ["10", "Euryale-1.3-L2-70B-GGUF", "[Euryale-1.3-L2-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", "4K", "Alpaca", "18/18 \u2713", "14/18", "\u2713", "\u2717", NaN], ["10", "bagel-dpo-34b-v0.2", "[bagel-dpo-34b-v0.2](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "34B", "HF", "4-bit", "~~200K~~ 4K", "Alpaca", "18/18 \u2713", "14/18", "\u2713", "\u2717", NaN], ["10", "nontoxic-bagel-34b-v0.2", "[nontoxic-bagel-34b-v0.2](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "34B", "HF", "4-bit", "~~200K~~ 4K", "Alpaca", "18/18 \u2713", "14/18", "\u2713", "\u2717", NaN], ["11", "miquella-120b", "[miquella-120b](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "120B", "GGUF", "IQ3_XXS", "~~32K~~ 4K", "Mistral", "18/18 \u2713", "13/18", "\u2713", "NaN", NaN], ["11", "sophosynthesis-70b-v1", "[sophosynthesis-70b-v1](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "EXL2", "4.85bpw", "4K", "Vicuna 1.1", "18/18 \u2713", "13/18", "\u2713", "\u2713", NaN], ["12", "Mixtral_11Bx2_MoE_19B", "[Mixtral_11Bx2_MoE_19B](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "2x11B", "HF", "\u2014", "~~200K~~ 4K", "Alpaca", "18/18 \u2713", "13/18", "\u2717", "\u2717", NaN], ["13", "GodziLLa2-70B-GGUF", "[GodziLLa2-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", "4K", "Alpaca", "18/18 \u2713", "12/18", "\u2713", "\u2713", NaN], ["14", "miquliz-120b-v2.0-iMat.GGUF", "[miquliz-120b-v2.0-iMat.GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "120B", "GGUF", "IQ2_XS", "~~32K~~ 4K", "Mistral", "18/18 \u2713", "11/18", "\u2717", "NaN", NaN], ["15", "Samantha-1.11-70B-GGUF", "[Samantha-1.11-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", "4K", "Vicuna 1.1", "18/18 \u2713", "10/18", "\u2717", "\u2717", NaN], ["16", "miquella-120b", "[miquella-120b](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "120B", "GGUF", "Q2_K", "~~32K~~ 4K", "Mistral", "17/18", "17/18", "\u2713", "NaN", NaN], ["17", "MegaDolphin-120b-exl2", "[MegaDolphin-120b-exl2](https://www.reddit.com/r/LocalLLaMA/comments/19d1fjp/llm_comparisontest_6_new_models_from_16b_to_120b/)", "120B", "EXL2", "3.0bpw", "4K", "ChatML", "17/18", "16/18", "\u2713", "NaN", NaN], ["17", "Airoboros-L2-70B-3.1.2-GGUF", "[Airoboros-L2-70B-3.1.2-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_K_M", "4K", "Llama 2 Chat", "17/18", "16/18", "\u2713", "\u2717", NaN], ["18", "Midnight-Miqu-70B-v1.0-GGUF", "[Midnight-Miqu-70B-v1.0-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "70B", "GGUF", "Q4_K_M", "~~32K~~ 4K", "Vicuna 1.1", "17/18", "16/18", "\u2717", "NaN", NaN], ["18", "Gemini Pro", "[Gemini Pro](https://www.reddit.com/r/LocalLLaMA/comments/18yp9u4/llm_comparisontest_api_edition_gpt4_vs_gemini_vs/)", "Gemini", "API", "NaN", "NaN", "NaN", "17/18", "16/18", "\u2717", "\u2717", NaN], ["19", "miquliz-120b-v2.0-i1-GGUF", "[miquliz-120b-v2.0-i1-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "120B", "GGUF", "IQ1_S", "~~32K~~ 4K", "Mistral", "17/18", "15/18", "\u2717", "NaN", NaN], ["19", "Nous-Hermes-2-Mixtral-8x7B-DPO-GGUF", "[Nous-Hermes-2-Mixtral-8x7B-DPO-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "8x7B", "GGUF", "Q4_K_M", "~~32K~~ 4K", "ChatML", "17/18", "15/18", "\u2717", "NaN", NaN], ["19", "SauerkrautLM-UNA-SOLAR-Instruct", "[SauerkrautLM-UNA-SOLAR-Instruct](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", "4K", "User-Ass.-Newlines", "17/18", "15/18", "\u2717", "\u2717", NaN], ["19", "UNA-SOLAR-10.7B-Instruct-v1.0", "[UNA-SOLAR-10.7B-Instruct-v1.0](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", "4K", "User-Ass.-Newlines", "17/18", "15/18", "\u2717", "\u2717", NaN], ["20", "Senku-70B-Full-GGUF", "[Senku-70B-Full-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "70B", "GGUF", "Q5_K_M", "~~32K~~ 4K", "ChatML", "17/18", "14/18", "\u2713", "NaN", NaN], ["21", "Rogue-Rose-103b-v0.2", "[Rogue-Rose-103b-v0.2](https://www.reddit.com/r/LocalLLaMA/comments/18ft8f5/updated_llm_comparisontest_with_new_rp_model/)", "103B", "EXL2", "3.2bpw", "4K", "Rogue Rose", "17/18", "14/18", "\u2717", "\u2717", NaN], ["21", "laserxtral", "[laserxtral](https://www.reddit.com/r/LocalLLaMA/comments/19d1fjp/llm_comparisontest_6_new_models_from_16b_to_120b/)", "4x7B", "GGUF", "Q6_K", "8K", "Alpaca", "17/18", "14/18", "\u2717", "NaN", NaN], ["21", "SOLAR-10.7B-Instruct-v1.0", "[SOLAR-10.7B-Instruct-v1.0](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", "4K", "User-Ass.-Newlines", "17/18", "14/18", "\u2717", "\u2717", NaN], ["22", "MiquMaid-v1-70B-GGUF", "[MiquMaid-v1-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "70B", "GGUF", "Q5_K_M", "~~32K~~ 4K", "Alpaca", "17/18", "13/18", "\u2713", "NaN", NaN], ["22", "miqu-1-70b", "[miqu-1-70b](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "70B", "GGUF", "Q5_K_M", "32K", "Mistral", "17/18", "13/18", "\u2717", "NaN", NaN], ["22", "miqu-1-70b", "[miqu-1-70b](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "70B", "GGUF", "Q4_K_M", "~~32K~~ 4K", "Mistral", "17/18", "13/18", "\u2717", "NaN", NaN], ["22", "MIstral-QUantized-70b_Miqu-1-70b-iMat.GGUF", "[MIstral-QUantized-70b_Miqu-1-70b-iMat.GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "70B", "GGUF", "Q4_K_S", "~~32K~~ 4K", "Mistral", "17/18", "13/18", "\u2717", "NaN", NaN], ["23", "Midnight-Rose-70B-v2.0.3-GGUF", "[Midnight-Rose-70B-v2.0.3-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "70B", "GGUF", "IQ3_XXS", "4K", "Vicuna 1.1", "17/18", "11/18", "\u2713", "NaN", NaN], ["24", "GPT-3.5 Turbo Instruct", "[GPT-3.5 Turbo Instruct](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "GPT-3.5", "API", "NaN", "NaN", "NaN", "17/18", "11/18", "\u2717", "\u2717", NaN], ["24", "mistral-small", "[mistral-small](https://www.reddit.com/r/LocalLLaMA/comments/18yp9u4/llm_comparisontest_api_edition_gpt4_vs_gemini_vs/)", "Mistral", "API", "NaN", "NaN", "NaN", "17/18", "11/18", "\u2717", "\u2717", NaN], ["25", "WestLake-7B-v2", "[WestLake-7B-v2](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "7B", "HF", "NaN", "4K", "ChatML", "17/18", "10/18", "\u2717", "NaN", NaN], ["25", "SOLARC-M-10.7B", "[SOLARC-M-10.7B](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", "4K", "User-Ass.-Newlines", "17/18", "10/18", "\u2717", "\u2717", NaN], ["26 \ud83c\udd95", "claude-3-sonnet-20240229", "[claude-3-sonnet-20240229](https://www.anthropic.com/claude)", "Claude 3 Sonnet", "API", "NaN", "NaN", "NaN", "17/18", "9/18", "\u2717", "\u2713", NaN], ["26", "Synthia-MoE-v3-Mixtral-8x7B", "[Synthia-MoE-v3-Mixtral-8x7B](https://www.reddit.com/r/LocalLLaMA/comments/18gz54r/llm_comparisontest_mixtral8x7b_mistral_decilm/)", "8x7B", "HF", "4-bit", "~~32K~~ 4K", "~~Synthia~~ Llama 2 Chat", "17/18", "9/18", "\u2717", "\u2717", NaN], ["27", "Nous-Hermes-2-Mixtral-8x7B-SFT", "[Nous-Hermes-2-Mixtral-8x7B-SFT](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "8x7B", "HF", "4-bit", "32K", "ChatML", "17/18", "5/18", "\u2713", "NaN", NaN], ["28", "miqu-1-70b-exl2", "[miqu-1-70b-exl2](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "70B", "EXL2", "3.0bpw", "~~32K~~ 4K", "Mistral", "16/18", "16/18", "\u2717", "NaN", NaN], ["29", "SOLAR-10.7B-Instruct-v1.0-uncensored", "[SOLAR-10.7B-Instruct-v1.0-uncensored](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", "4K", "User-Ass.-Newlines", "16/18", "15/18", "\u2717", "\u2717", NaN], ["30", "bagel-dpo-8x7b-v0.2", "[bagel-dpo-8x7b-v0.2](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "8x7B", "HF", "4-bit", "~~200K~~ 4K", "Alpaca", "16/18", "14/18", "\u2713", "\u2717", NaN], ["31", "dolphin-2.2-70B-GGUF", "[dolphin-2.2-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", "4K", "ChatML", "16/18", "14/18", "\u2717", "\u2713", NaN], ["31", "miqu-1-103b-i1-GGUF", "[miqu-1-103b-i1-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "103B", "GGUF", "IQ2_XS", "~~32K~~ 4K", "Mistral", "16/18", "14/18", "\u2717", "NaN", NaN], ["31", "WestLake-7B-v2-laser", "[WestLake-7B-v2-laser](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "7B", "HF", "NaN", "4K", "ChatML", "16/18", "14/18", "\u2717", "NaN", NaN], ["32", "Beyonder-4x7B-v2-GGUF", "[Beyonder-4x7B-v2-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/19d1fjp/llm_comparisontest_6_new_models_from_16b_to_120b/)", "4x7B", "GGUF", "Q8_0", "8K", "ChatML", "16/18", "13/18", "\u2713", "NaN", NaN], ["33", "mistral-ft-optimized-1218", "[mistral-ft-optimized-1218](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", "~~32K~~ 8K", "Alpaca", "16/18", "13/18", "\u2717", "\u2713", NaN], ["34", "SauerkrautLM-SOLAR-Instruct", "[SauerkrautLM-SOLAR-Instruct](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", "4K", "User-Ass.-Newlines", "16/18", "13/18", "\u2717", "\u2717", NaN], ["34", "OpenHermes-2.5-Mistral-7B", "[OpenHermes-2.5-Mistral-7B](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", "~~32K~~ 8K", "ChatML", "16/18", "13/18", "\u2717", "\u2717", NaN], ["35", "Nous-Hermes-2-Mixtral-8x7B-SFT-GGUF", "[Nous-Hermes-2-Mixtral-8x7B-SFT-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "8x7B", "GGUF", "Q4_K_M", "~~32K~~ 4K", "ChatML", "16/18", "12/18", "\u2713", "NaN", NaN], ["36", "SOLARC-MOE-10.7Bx4", "[SOLARC-MOE-10.7Bx4](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "4x11B", "HF", "4-bit", "4K", "User-Ass.-Newlines", "16/18", "12/18", "\u2717", "\u2717", NaN], ["36", "Nous-Hermes-2-SOLAR-10.7B", "[Nous-Hermes-2-SOLAR-10.7B](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", "4K", "User-Ass.-Newlines", "16/18", "12/18", "\u2717", "\u2717", NaN], ["36", "Sakura-SOLAR-Instruct", "[Sakura-SOLAR-Instruct](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", "4K", "User-Ass.-Newlines", "16/18", "12/18", "\u2717", "\u2717", NaN], ["36", "Mistral-7B-Instruct-v0.2", "[Mistral-7B-Instruct-v0.2](https://www.reddit.com/r/LocalLLaMA/comments/18gz54r/llm_comparisontest_mixtral8x7b_mistral_decilm/)", "7B", "HF", "\u2014", "32K", "Mistral", "16/18", "12/18", "\u2717", "\u2717", NaN], ["37", "DeciLM-7B-instruct", "[DeciLM-7B-instruct](https://www.reddit.com/r/LocalLLaMA/comments/18gz54r/llm_comparisontest_mixtral8x7b_mistral_decilm/)", "7B", "HF", "\u2014", "32K", "Mistral", "16/18", "11/18", "\u2717", "\u2717", NaN], ["37", "Marcoroni-7B-v3", "[Marcoroni-7B-v3](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", "~~32K~~ 8K", "Alpaca", "16/18", "11/18", "\u2717", "\u2717", NaN], ["37", "SauerkrautLM-7b-HerO", "[SauerkrautLM-7b-HerO](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", "~~32K~~ 8K", "ChatML", "16/18", "11/18", "\u2717", "\u2717", NaN], ["38", "mistral-medium", "[mistral-medium](https://www.reddit.com/r/LocalLLaMA/comments/18yp9u4/llm_comparisontest_api_edition_gpt4_vs_gemini_vs/)", "Mistral", "API", "NaN", "NaN", "NaN", "15/18", "17/18", "\u2717", "\u2717", NaN], ["39", "mistral-ft-optimized-1227", "[mistral-ft-optimized-1227](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", "~~32K~~ 8K", "Alpaca", "15/18", "14/18", "\u2717", "\u2713", NaN], ["40", "GPT-3.5 Turbo", "[GPT-3.5 Turbo](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "GPT-3.5", "API", "NaN", "NaN", "NaN", "15/18", "14/18", "\u2717", "\u2717", NaN], ["41", "dolphin-2.5-mixtral-8x7b", "[dolphin-2.5-mixtral-8x7b](https://www.reddit.com/r/LocalLLaMA/comments/18gz54r/llm_comparisontest_mixtral8x7b_mistral_decilm/)", "8x7B", "HF", "4-bit", "~~32K~~ 4K", "ChatML", "15/18", "13/18", "\u2717", "\u2713", NaN], ["42", "Starling-LM-7B-alpha", "[Starling-LM-7B-alpha](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", "8K", "OpenChat (GPT4 Correct)", "15/18", "13/18", "\u2717", "\u2717", NaN], ["43", "dolphin-2.6-mistral-7b-dpo", "[dolphin-2.6-mistral-7b-dpo](https://www.reddit.com/r/LocalLLaMA/comments/18w9hak/llm_comparisontest_brand_new_models_for_2024/)", "7B", "HF", "\u2014", "16K", "ChatML", "15/18", "12/18", "\u2717", "\u2717", NaN], ["44", "Mixtral_7Bx2_MoE", "[Mixtral_7Bx2_MoE](https://www.reddit.com/r/LocalLLaMA/comments/19d1fjp/llm_comparisontest_6_new_models_from_16b_to_120b/)", "2x7B", "HF", "\u2014", "8K", "ChatML", "15/18", "11/18", "\u2713", "NaN", NaN], ["45", "Nous-Hermes-2-Mixtral-8x7B-DPO", "[Nous-Hermes-2-Mixtral-8x7B-DPO](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "8x7B", "HF", "4-bit", "32K", "ChatML", "15/18", "10/18", "\u2713", "NaN", NaN], ["46", "sparsetral-16x7B-v2", "[sparsetral-16x7B-v2](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "16x7B", "HF", "NaN", "4K", "ChatML", "15/18", "7/18", "\u2713", "NaN", NaN], ["47", "openchat-3.5-1210", "[openchat-3.5-1210](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", "8K", "OpenChat (GPT4 Correct)", "15/18", "7/18", "\u2717", "\u2717", NaN], ["48", "dolphin-2.7-mixtral-8x7b", "[dolphin-2.7-mixtral-8x7b](https://www.reddit.com/r/LocalLLaMA/comments/18w9hak/llm_comparisontest_brand_new_models_for_2024/)", "8x7B", "HF", "4-bit", "32K", "ChatML", "15/18", "6/18", "\u2717", "\u2717", NaN], ["49", "dolphin-2.6-mixtral-8x7b", "[dolphin-2.6-mixtral-8x7b](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "8x7B", "HF", "4-bit", "~~32K~~ 16K", "ChatML", "14/18", "12/18", "\u2717", "\u2717", NaN]];

    // Define the dt_args
    let dt_args = {"dom": "lrtip", "order": [], "initComplete": function () {
    // Apply the search
    this.api()
        .columns()
        .every(function () {
            const that = this;

            $('input', this.header()).on('keyup change clear', function () {
                if (that.search() !== this.value) {
                    that.search(this.value).draw();
                }
            });
        });
}
};
    dt_args["data"] = data;

    $(document).ready(function () {
        // Setup - add a text input to each header or footer cell
$('#99d7f90a-d37f-4e27-98da-c6db13822d1b thead th').each(function () {
    let title = $(this).text();
    $(this).html('<input type="text" placeholder="Search ' +
        // We use encodeURI to avoid this LGTM error:
        // https://lgtm.com/rules/1511866576920/
        encodeURI(title).replaceAll("%20", " ") +
        '" />');
});

        $('#99d7f90a-d37f-4e27-98da-c6db13822d1b').DataTable(dt_args);
    });
</script>
</div>
