<table id="itables_a640ed4d_402b_477d_8a9f_fcd14146fa18" class="display cell-border" data-quarto-disable-processing="true" style="width:100%;margin:auto">
<thead><th>Rank</th><th>Model-Name</th><th>Model</th><th>Size</th><th>Format</th><th>Quant</th><th>Context</th><th>Prompt</th><th>1st Score</th><th>2nd Score</th><th>OK</th><th>+/-</th></thead><tbody><tr><td>Loading... (need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td></tr></tbody>

</table>
<link href="https://www.unpkg.com/dt_for_itables@2.0.1/dt_bundle.css" rel="stylesheet">
<script type="module">
    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.0.1/dt_bundle.js';

    document.querySelectorAll("#itables_a640ed4d_402b_477d_8a9f_fcd14146fa18:not(.dataTable)").forEach(table => {
        // Define the table data
        const data = [["1", "claude-3-opus-20240229", "[claude-3-opus-20240229](https://www.anthropic.com/claude)", "Claude 3 Opus", "API", "", " ", " ", "18/18 \u2713", "18/18 \u2713", "\u2717", "\u2713"], ["1", "GPT-4", "[GPT-4](https://www.reddit.com/r/LocalLLaMA/comments/18yp9u4/llm_comparisontest_api_edition_gpt4_vs_gemini_vs/)", "GPT-4", "API", "", " ", " ", "18/18 \u2713", "18/18 \u2713", "\u2713", "\u2713"], ["1", "mistral-large-2402", "[mistral-large-2402](https://mistral.ai/)", "Mistral", "API", "", " ", " ", "18/18 \u2713", "18/18 \u2713", "\u2717", "\u2717"], ["1", "miquliz-120b-v2.0", "[miquliz-120b-v2.0](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "120B", "EXL2", "3.0bpw", " ~~32K~~ 4K-12K ", " Mistral ", "18/18 \u2713", "18/18 \u2713", "\u2713", "\u2713"], ["1", "goliath-120b-GGUF", "[goliath-120b-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "120B", "GGUF", "Q2_K", " 4K ", " Vicuna 1.1 ", "18/18 \u2713", "18/18 \u2713", "\u2713", "\u2713"], ["1", "Tess-XL-v1.0-GGUF", "[Tess-XL-v1.0-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "120B", "GGUF", "Q2_K", " 4K ", " Synthia ", "18/18 \u2713", "18/18 \u2713", "\u2713", "\u2713"], ["1", "Nous-Capybara-34B-GGUF", "[Nous-Capybara-34B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "34B", "GGUF", "Q4_0", " 16K ", " Vicuna 1.1 ", "18/18 \u2713", "18/18 \u2713", "\u2713", "\u2713"], ["1", "Venus-120b-v1.0", "[Venus-120b-v1.0](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "120B", "EXL2", "3.0bpw", " 4K ", " Alpaca ", "18/18 \u2713", "18/18 \u2713", "\u2713", "\u2717"], ["2", "wolfram/miqu-1-120b", "[wolfram/miqu-1-120b](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "120B", "EXL2", "3.0bpw", " 4K ", " Mistral ", "18/18 \u2713", "18/18 \u2713", "\u2717", ""], ["3", "miquella-120b-3.0bpw-h6-exl2", "[miquella-120b-3.0bpw-h6-exl2](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "120B", "EXL2", "3.0bpw", " ~~32K~~ 4K ", " Mistral ", "18/18 \u2713", "17/18", "\u2713", "\u2713"], ["3", "lzlv_70B-GGUF", "[lzlv_70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", " 4K ", " Vicuna 1.1 ", "18/18 \u2713", "17/18", "\u2713", "\u2713"], ["4", "Mixtral_34Bx2_MoE_60B", "[Mixtral_34Bx2_MoE_60B](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "2x34B", "HF", "4-bit", " ~~200K~~ 4K ", " Alpaca ", "18/18 \u2713", "17/18", "\u2713", "\u2717"], ["5", "miquliz-120b-xs.gguf", "[miquliz-120b-xs.gguf](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "120B", "GGUF", "IQ2_XS", " ~~32K~~ 4K ", " Mistral ", "18/18 \u2713", "17/18", "\u2717", ""], ["6", "GPT-4 Turbo", "[GPT-4 Turbo](https://www.reddit.com/r/LocalLLaMA/comments/18yp9u4/llm_comparisontest_api_edition_gpt4_vs_gemini_vs/)", "GPT-4", "API", "", " ", " ", "18/18 \u2713", "16/18", "\u2713", "\u2713"], ["6", "chronos007-70B-GGUF", "[chronos007-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", " 4K ", " Alpaca ", "18/18 \u2713", "16/18", "\u2713", "\u2713"], ["6", "SynthIA-70B-v1.5-GGUF", "[SynthIA-70B-v1.5-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", " 4K ", " SynthIA ", "18/18 \u2713", "16/18", "\u2713", "\u2713"], ["6", "Gembo-v1-70b-GGUF", "[Gembo-v1-70b-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "70B", "GGUF", "Q5_K_M", " 4K ", " Alpaca ", "18/18 \u2713", "16/18", "\u2713", ""], ["6", "bagel-34b-v0.2", "[bagel-34b-v0.2](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "34B", "HF", "4-bit", " ~~200K~~ 4K ", " Alpaca ", "18/18 \u2713", "16/18", "\u2713", "\u2717"], ["7", "Mixtral-8x7B-Instruct-v0.1", "[Mixtral-8x7B-Instruct-v0.1](https://www.reddit.com/r/LocalLLaMA/comments/18gz54r/llm_comparisontest_mixtral8x7b_mistral_decilm/)", "8x7B", "HF", "4-bit", " ~~32K~~ 4K ", " Mixtral ", "18/18 \u2713", "16/18", "\u2717", "\u2713"], ["8", "dolphin-2_2-yi-34b-GGUF", "[dolphin-2_2-yi-34b-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "34B", "GGUF", "Q4_0", " 16K ", " ChatML ", "18/18 \u2713", "15/18", "\u2717", "\u2717"], ["9", "StellarBright-GGUF", "[StellarBright-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", " 4K ", " Vicuna 1.1 ", "18/18 \u2713", "14/18", "\u2713", "\u2713"], ["10", "Dawn-v2-70B-GGUF", "[Dawn-v2-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", " 4K ", " Alpaca ", "18/18 \u2713", "14/18", "\u2713", "\u2717"], ["10", "Euryale-1.3-L2-70B-GGUF", "[Euryale-1.3-L2-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", " 4K ", " Alpaca ", "18/18 \u2713", "14/18", "\u2713", "\u2717"], ["10", "bagel-dpo-34b-v0.2", "[bagel-dpo-34b-v0.2](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "34B", "HF", "4-bit", " ~~200K~~ 4K ", " Alpaca ", "18/18 \u2713", "14/18", "\u2713", "\u2717"], ["10", "nontoxic-bagel-34b-v0.2", "[nontoxic-bagel-34b-v0.2](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "34B", "HF", "4-bit", " ~~200K~~ 4K ", " Alpaca ", "18/18 \u2713", "14/18", "\u2713", "\u2717"], ["11", "miquella-120b", "[miquella-120b](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "120B", "GGUF", "IQ3_XXS", " ~~32K~~ 4K ", " Mistral ", "18/18 \u2713", "13/18", "\u2713", ""], ["11", "sophosynthesis-70b-v1", "[sophosynthesis-70b-v1](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "EXL2", "4.85bpw", " 4K ", " Vicuna 1.1 ", "18/18 \u2713", "13/18", "\u2713", "\u2713"], ["12", "Mixtral_11Bx2_MoE_19B", "[Mixtral_11Bx2_MoE_19B](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "2x11B", "HF", "\u2014", " ~~200K~~ 4K ", " Alpaca ", "18/18 \u2713", "13/18", "\u2717", "\u2717"], ["13", "GodziLLa2-70B-GGUF", "[GodziLLa2-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", " 4K ", " Alpaca ", "18/18 \u2713", "12/18", "\u2713", "\u2713"], ["14", "miquliz-120b-v2.0-iMat.GGUF", "[miquliz-120b-v2.0-iMat.GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "120B", "GGUF", "IQ2_XS", " ~~32K~~ 4K ", " Mistral ", "18/18 \u2713", "11/18", "\u2717", ""], ["15", "Samantha-1.11-70B-GGUF", "[Samantha-1.11-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", " 4K ", " Vicuna 1.1 ", "18/18 \u2713", "10/18", "\u2717", "\u2717"], ["16", "miquella-120b", "[miquella-120b](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "120B", "GGUF", "Q2_K", " ~~32K~~ 4K ", " Mistral ", "17/18", "17/18", "\u2713", ""], ["17", "MegaDolphin-120b-exl2", "[MegaDolphin-120b-exl2](https://www.reddit.com/r/LocalLLaMA/comments/19d1fjp/llm_comparisontest_6_new_models_from_16b_to_120b/)", "120B", "EXL2", "3.0bpw", " 4K ", " ChatML ", "17/18", "16/18", "\u2713", ""], ["17", "Airoboros-L2-70B-3.1.2-GGUF", "[Airoboros-L2-70B-3.1.2-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_K_M", " 4K ", " Llama 2 Chat ", "17/18", "16/18", "\u2713", "\u2717"], ["18", "Midnight-Miqu-70B-v1.0-GGUF", "[Midnight-Miqu-70B-v1.0-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "70B", "GGUF", "Q4_K_M", " ~~32K~~ 4K ", " Vicuna 1.1 ", "17/18", "16/18", "\u2717", ""], ["18", "Gemini Pro", "[Gemini Pro](https://www.reddit.com/r/LocalLLaMA/comments/18yp9u4/llm_comparisontest_api_edition_gpt4_vs_gemini_vs/)", "Gemini", "API", "", " ", " ", "17/18", "16/18", "\u2717", "\u2717"], ["19", "miquliz-120b-v2.0-i1-GGUF", "[miquliz-120b-v2.0-i1-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "120B", "GGUF", "IQ1_S", " ~~32K~~ 4K ", " Mistral ", "17/18", "15/18", "\u2717", ""], ["19", "Nous-Hermes-2-Mixtral-8x7B-DPO-GGUF", "[Nous-Hermes-2-Mixtral-8x7B-DPO-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "8x7B", "GGUF", "Q4_K_M", " ~~32K~~ 4K ", " ChatML ", "17/18", "15/18", "\u2717", ""], ["19", "SauerkrautLM-UNA-SOLAR-Instruct", "[SauerkrautLM-UNA-SOLAR-Instruct](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", " 4K ", " User-Ass.-Newlines ", "17/18", "15/18", "\u2717", "\u2717"], ["19", "UNA-SOLAR-10.7B-Instruct-v1.0", "[UNA-SOLAR-10.7B-Instruct-v1.0](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", " 4K ", " User-Ass.-Newlines ", "17/18", "15/18", "\u2717", "\u2717"], ["20", "Senku-70B-Full-GGUF", "[Senku-70B-Full-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "70B", "GGUF", "Q5_K_M", " ~~32K~~ 4K ", " ChatML ", "17/18", "14/18", "\u2713", ""], ["21", "Rogue-Rose-103b-v0.2", "[Rogue-Rose-103b-v0.2](https://www.reddit.com/r/LocalLLaMA/comments/18ft8f5/updated_llm_comparisontest_with_new_rp_model/)", "103B", "EXL2", "3.2bpw", " 4K ", " Rogue Rose ", "17/18", "14/18", "\u2717", "\u2717"], ["21", "laserxtral", "[laserxtral](https://www.reddit.com/r/LocalLLaMA/comments/19d1fjp/llm_comparisontest_6_new_models_from_16b_to_120b/)", "4x7B", "GGUF", "Q6_K", " 8K ", " Alpaca ", "17/18", "14/18", "\u2717", ""], ["21", "SOLAR-10.7B-Instruct-v1.0", "[SOLAR-10.7B-Instruct-v1.0](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", " 4K ", " User-Ass.-Newlines ", "17/18", "14/18", "\u2717", "\u2717"], ["22", "MiquMaid-v1-70B-GGUF", "[MiquMaid-v1-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "70B", "GGUF", "Q5_K_M", " ~~32K~~ 4K ", " Alpaca ", "17/18", "13/18", "\u2713", ""], ["22", "miqu-1-70b", "[miqu-1-70b](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "70B", "GGUF", "Q5_K_M", " 32K ", " Mistral ", "17/18", "13/18", "\u2717", ""], ["22", "miqu-1-70b", "[miqu-1-70b](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "70B", "GGUF", "Q4_K_M", " ~~32K~~ 4K ", " Mistral ", "17/18", "13/18", "\u2717", ""], ["22", "MIstral-QUantized-70b_Miqu-1-70b-iMat.GGUF", "[MIstral-QUantized-70b_Miqu-1-70b-iMat.GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "70B", "GGUF", "Q4_K_S", " ~~32K~~ 4K ", " Mistral ", "17/18", "13/18", "\u2717", ""], ["23", "Midnight-Rose-70B-v2.0.3-GGUF", "[Midnight-Rose-70B-v2.0.3-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "70B", "GGUF", "IQ3_XXS", " 4K ", " Vicuna 1.1 ", "17/18", "11/18", "\u2713", ""], ["24", "GPT-3.5 Turbo Instruct", "[GPT-3.5 Turbo Instruct](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "GPT-3.5", "API", "", " ", " ", "17/18", "11/18", "\u2717", "\u2717"], ["24", "mistral-small", "[mistral-small](https://www.reddit.com/r/LocalLLaMA/comments/18yp9u4/llm_comparisontest_api_edition_gpt4_vs_gemini_vs/)", "Mistral", "API", "", " ", " ", "17/18", "11/18", "\u2717", "\u2717"], ["25", "WestLake-7B-v2", "[WestLake-7B-v2](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "7B", "HF", "", " 4K ", " ChatML ", "17/18", "10/18", "\u2717", ""], ["25", "SOLARC-M-10.7B", "[SOLARC-M-10.7B](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", " 4K ", " User-Ass.-Newlines ", "17/18", "10/18", "\u2717", "\u2717"], ["26", "claude-3-sonnet-20240229", "[claude-3-sonnet-20240229](https://www.anthropic.com/claude)", "Claude 3 Sonnet", "API", "", " ", " ", "17/18", "9/18", "\u2717", "\u2713"], ["26", "Synthia-MoE-v3-Mixtral-8x7B", "[Synthia-MoE-v3-Mixtral-8x7B](https://www.reddit.com/r/LocalLLaMA/comments/18gz54r/llm_comparisontest_mixtral8x7b_mistral_decilm/)", "8x7B", "HF", "4-bit", " ~~32K~~ 4K ", " ~~Synthia~~ Llama 2 Chat ", "17/18", "9/18", "\u2717", "\u2717"], ["27", "Nous-Hermes-2-Mixtral-8x7B-SFT", "[Nous-Hermes-2-Mixtral-8x7B-SFT](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "8x7B", "HF", "4-bit", " 32K ", " ChatML ", "17/18", "5/18", "\u2713", ""], ["28", "miqu-1-70b-exl2", "[miqu-1-70b-exl2](https://www.reddit.com/r/LocalLLaMA/comments/1aix93e/llm_comparisontest_miqu_miqu_miqu_miquella_maid/)", "70B", "EXL2", "3.0bpw", " ~~32K~~ 4K ", " Mistral ", "16/18", "16/18", "\u2717", ""], ["29", "SOLAR-10.7B-Instruct-v1.0-uncensored", "[SOLAR-10.7B-Instruct-v1.0-uncensored](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", " 4K ", " User-Ass.-Newlines ", "16/18", "15/18", "\u2717", "\u2717"], ["30", "bagel-dpo-8x7b-v0.2", "[bagel-dpo-8x7b-v0.2](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "8x7B", "HF", "4-bit", " ~~200K~~ 4K ", " Alpaca ", "16/18", "14/18", "\u2713", "\u2717"], ["31", "dolphin-2.2-70B-GGUF", "[dolphin-2.2-70B-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "70B", "GGUF", "Q4_0", " 4K ", " ChatML ", "16/18", "14/18", "\u2717", "\u2713"], ["31", "miqu-1-103b-i1-GGUF", "[miqu-1-103b-i1-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "103B", "GGUF", "IQ2_XS", " ~~32K~~ 4K ", " Mistral ", "16/18", "14/18", "\u2717", ""], ["31", "WestLake-7B-v2-laser", "[WestLake-7B-v2-laser](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "7B", "HF", "", " 4K ", " ChatML ", "16/18", "14/18", "\u2717", ""], ["32", "Beyonder-4x7B-v2-GGUF", "[Beyonder-4x7B-v2-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/19d1fjp/llm_comparisontest_6_new_models_from_16b_to_120b/)", "4x7B", "GGUF", "Q8_0", " 8K ", " ChatML ", "16/18", "13/18", "\u2713", ""], ["33", "mistral-ft-optimized-1218", "[mistral-ft-optimized-1218](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", " ~~32K~~ 8K ", " Alpaca ", "16/18", "13/18", "\u2717", "\u2713"], ["34", "SauerkrautLM-SOLAR-Instruct", "[SauerkrautLM-SOLAR-Instruct](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", " 4K ", " User-Ass.-Newlines ", "16/18", "13/18", "\u2717", "\u2717"], ["34", "OpenHermes-2.5-Mistral-7B", "[OpenHermes-2.5-Mistral-7B](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", " ~~32K~~ 8K ", " ChatML ", "16/18", "13/18", "\u2717", "\u2717"], ["35", "Nous-Hermes-2-Mixtral-8x7B-SFT-GGUF", "[Nous-Hermes-2-Mixtral-8x7B-SFT-GGUF](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "8x7B", "GGUF", "Q4_K_M", " ~~32K~~ 4K ", " ChatML ", "16/18", "12/18", "\u2713", ""], ["36", "SOLARC-MOE-10.7Bx4", "[SOLARC-MOE-10.7Bx4](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "4x11B", "HF", "4-bit", " 4K ", " User-Ass.-Newlines ", "16/18", "12/18", "\u2717", "\u2717"], ["36", "Nous-Hermes-2-SOLAR-10.7B", "[Nous-Hermes-2-SOLAR-10.7B](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", " 4K ", " User-Ass.-Newlines ", "16/18", "12/18", "\u2717", "\u2717"], ["36", "Sakura-SOLAR-Instruct", "[Sakura-SOLAR-Instruct](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "11B", "HF", "\u2014", " 4K ", " User-Ass.-Newlines ", "16/18", "12/18", "\u2717", "\u2717"], ["36", "Mistral-7B-Instruct-v0.2", "[Mistral-7B-Instruct-v0.2](https://www.reddit.com/r/LocalLLaMA/comments/18gz54r/llm_comparisontest_mixtral8x7b_mistral_decilm/)", "7B", "HF", "\u2014", " 32K ", " Mistral ", "16/18", "12/18", "\u2717", "\u2717"], ["37", "DeciLM-7B-instruct", "[DeciLM-7B-instruct](https://www.reddit.com/r/LocalLLaMA/comments/18gz54r/llm_comparisontest_mixtral8x7b_mistral_decilm/)", "7B", "HF", "\u2014", " 32K ", " Mistral ", "16/18", "11/18", "\u2717", "\u2717"], ["37", "Marcoroni-7B-v3", "[Marcoroni-7B-v3](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", " ~~32K~~ 8K ", " Alpaca ", "16/18", "11/18", "\u2717", "\u2717"], ["37", "SauerkrautLM-7b-HerO", "[SauerkrautLM-7b-HerO](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", " ~~32K~~ 8K ", " ChatML ", "16/18", "11/18", "\u2717", "\u2717"], ["38", "mistral-medium", "[mistral-medium](https://www.reddit.com/r/LocalLLaMA/comments/18yp9u4/llm_comparisontest_api_edition_gpt4_vs_gemini_vs/)", "Mistral", "API", "", " ", " ", "15/18", "17/18", "\u2717", "\u2717"], ["39", "mistral-ft-optimized-1227", "[mistral-ft-optimized-1227](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", " ~~32K~~ 8K ", " Alpaca ", "15/18", "14/18", "\u2717", "\u2713"], ["40", "GPT-3.5 Turbo", "[GPT-3.5 Turbo](https://www.reddit.com/r/LocalLLaMA/comments/185ff51/big_llm_comparisontest_3x_120b_12x_70b_2x_34b/)", "GPT-3.5", "API", "", " ", " ", "15/18", "14/18", "\u2717", "\u2717"], ["41", "dolphin-2.5-mixtral-8x7b", "[dolphin-2.5-mixtral-8x7b](https://www.reddit.com/r/LocalLLaMA/comments/18gz54r/llm_comparisontest_mixtral8x7b_mistral_decilm/)", "8x7B", "HF", "4-bit", " ~~32K~~ 4K ", " ChatML ", "15/18", "13/18", "\u2717", "\u2713"], ["42", "Starling-LM-7B-alpha", "[Starling-LM-7B-alpha](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", " 8K ", " OpenChat (GPT4 Correct) ", "15/18", "13/18", "\u2717", "\u2717"], ["43", "dolphin-2.6-mistral-7b-dpo", "[dolphin-2.6-mistral-7b-dpo](https://www.reddit.com/r/LocalLLaMA/comments/18w9hak/llm_comparisontest_brand_new_models_for_2024/)", "7B", "HF", "\u2014", " 16K ", " ChatML ", "15/18", "12/18", "\u2717", "\u2717"], ["44", "Mixtral_7Bx2_MoE", "[Mixtral_7Bx2_MoE](https://www.reddit.com/r/LocalLLaMA/comments/19d1fjp/llm_comparisontest_6_new_models_from_16b_to_120b/)", "2x7B", "HF", "\u2014", " 8K ", " ChatML ", "15/18", "11/18", "\u2713", ""], ["45", "Nous-Hermes-2-Mixtral-8x7B-DPO", "[Nous-Hermes-2-Mixtral-8x7B-DPO](https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/)", "8x7B", "HF", "4-bit", " 32K ", " ChatML ", "15/18", "10/18", "\u2713", ""], ["46", "sparsetral-16x7B-v2", "[sparsetral-16x7B-v2](https://www.reddit.com/r/LocalLLaMA/comments/1b5vp2e/llm_comparisontest_17_new_models_64_total_ranked/)", "16x7B", "HF", "", " 4K ", " ChatML ", "15/18", "7/18", "\u2713", ""], ["47", "openchat-3.5-1210", "[openchat-3.5-1210](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "7B", "HF", "\u2014", " 8K ", " OpenChat (GPT4 Correct) ", "15/18", "7/18", "\u2717", "\u2717"], ["48", "dolphin-2.7-mixtral-8x7b", "[dolphin-2.7-mixtral-8x7b](https://www.reddit.com/r/LocalLLaMA/comments/18w9hak/llm_comparisontest_brand_new_models_for_2024/)", "8x7B", "HF", "4-bit", " 32K ", " ChatML ", "15/18", "6/18", "\u2717", "\u2717"], ["49", "dolphin-2.6-mixtral-8x7b", "[dolphin-2.6-mixtral-8x7b](https://www.reddit.com/r/LocalLLaMA/comments/18u122l/llm_comparisontest_ranking_updated_with_10_new/)", "8x7B", "HF", "4-bit", " ~~32K~~ 16K ", " ChatML ", "14/18", "12/18", "\u2717", "\u2717"], [" 1 \ud83c\udd95   ", "turboderp/Llama-3-70B-Instruct-exl2", "[turboderp/Llama-3-70B-Instruct-exl2](https://huggingface.co/turboderp/Llama-3-70B-Instruct-exl2)", "70B", "EXL2", "5.0bpw/4.5bpw", "NaN", "NaN", "18/18 \u2713", "18/18 \u2713", "\u2713", "\u2713"], [" 2 \ud83c\udd95   ", "casperhansen/llama-3-70b-instruct-awq", "[casperhansen/llama-3-70b-instruct-awq](https://huggingface.co/casperhansen/llama-3-70b-instruct-awq)", "70B", "AWQ", "4-bit", "NaN", "NaN", "18/18 \u2713", "17/18", "\u2713", "\u2713"], [" 2 \ud83c\udd95   ", "turboderp/Llama-3-70B-Instruct-exl2", "[turboderp/Llama-3-70B-Instruct-exl2](https://huggingface.co/turboderp/Llama-3-70B-Instruct-exl2)", "70B", "EXL2", "4.0bpw", "NaN", "NaN", "18/18 \u2713", "17/18", "\u2713", "\u2713"], [" 3 \ud83c\udd95   ", "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF", "[MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF](https://huggingface.co/MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF)", "70B", "GGUF", "Q8_0/Q6_K/Q5_K_M/Q5_K_S/Q4_K_M/Q4_K_S/IQ4_XS", "NaN", "NaN", "18/18 \u2713", "16/18", "\u2713", "\u2713"], [" 3 \ud83c\udd95   ", "NousResearch/Meta-Llama-3-70B-Instruct-GGUF", "[NousResearch/Meta-Llama-3-70B-Instruct-GGUF](https://huggingface.co/NousResearch/Meta-Llama-3-70B-Instruct-GGUF)", "70B", "GGUF", "Q5_K_M", "NaN", "NaN", "18/18 \u2713", "16/18", "\u2713", "\u2713"], [" 4 \ud83c\udd95   ", "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF", "[MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF](https://huggingface.co/MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF)", "70B", "GGUF", "Q3_K_S/IQ3_XS/IQ2_XS", "NaN", "NaN", "18/18 \u2713", "15/18", "\u2713", "\u2713"], [" 5 \ud83c\udd95   ", "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF", "[MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF](https://huggingface.co/MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF)", "70B", "GGUF", "Q3_K_M", "NaN", "NaN", "18/18 \u2713", "13/18", "\u2713", "\u2713"], [" 6 \ud83c\udd95   ", "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF", "[MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF](https://huggingface.co/MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF)", "70B", "GGUF", "Q3_K_L", "NaN", "NaN", "18/18 \u2713", "11/18", "\u2713", "\u2713"], [" 7 \ud83c\udd95   ", "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF", "[MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF](https://huggingface.co/MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF)", "70B", "GGUF", "Q2_K", "NaN", "NaN", "17/18", "14/18", "\u2713", "\u2713"], [" 8 \ud83c\udd95   ", "meta-llama/Meta-Llama-3-8B-Instruct", "[meta-llama/Meta-Llama-3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)", "8B", "HF", "\u2014", "NaN", "NaN", "17/18", "9/18", "\u2713", "\u2717"], [" 8 \ud83c\udd95   ", "turboderp/Llama-3-8B-Instruct-exl2", "[turboderp/Llama-3-8B-Instruct-exl2](https://huggingface.co/turboderp/Llama-3-8B-Instruct-exl2)", "8B", "EXL2", "6.0bpw", "NaN", "NaN", "17/18", "9/18", "\u2713", "\u2717"], [" 9 \ud83c\udd95   ", "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF", "[MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF](https://huggingface.co/MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF)", "70B", "GGUF", "IQ1_S", "NaN", "NaN", "16/18", "13/18", "\u2713", "\u2717"], [" 10\ud83c\udd95   ", "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF", "[MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF](https://huggingface.co/MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF)", "70B", "GGUF", "IQ1_M", "NaN", "NaN", "15/18", "12/18", "\u2713", "\u2717"]];

        // Define the dt_args
        let dt_args = {"layout": {"topStart": "pageLength", "topEnd": "search", "bottomStart": "info", "bottomEnd": "paging", "top1": "searchBuilder"}, "order": [], "warn_on_dom": true, "initComplete": function () {
    // Apply the search
    this.api()
        .columns()
        .every(function () {
            const that = this;

            $('input', this.header()).on('keyup change clear', function () {
                if (that.search() !== this.value) {
                    that.search(this.value).draw();
                }
            });
        });
}
};
        dt_args["data"] = data;

        // Setup - add a text input to each header or footer cell
$('#itables_a640ed4d_402b_477d_8a9f_fcd14146fa18:not(.dataTable) thead th').each(function () {
    let title = $(this).text();
    $(this).html('<input type="text" placeholder="Search ' +
        // We use encodeURI to avoid this LGTM error:
        // https://lgtm.com/rules/1511866576920/
        encodeURI(title).replaceAll("%20", " ") +
        '" />');
});

        new DataTable(table, dt_args);
    });
</script>
